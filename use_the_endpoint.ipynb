{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5263e9f8-5c6c-40bc-9f90-e61861ef021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sse_starlette -q\n",
    "!pip install langserve -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d3aef5-85f9-4255-b5dd-77183326034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2cbec47-465d-44b3-b01a-846c342eb285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': {'answer': 'LangChain is a platform that allows developers to build applications using Large Language Models (LLMs) through composability. It provides tools for creating chains of calls to LLMs or other utilities, as well as agents that can make decisions based on LLM outputs. LangChain supports various use cases such as personal assistants, question answering, chatbots, querying tabular data, interacting with APIs, extraction, summarization, and evaluation of generative models.', 'source_documents': [{'page_content': '{\\'id\\': \\'492be6fe9516-2\\', \\'text\\': \\'A chain in LangChain is made up of links, which can be either primitives like LLMs or other chains.\\\\nThe most core type of chain is an LLMChain, which consists of a PromptTemplate and an LLM.\\\\nExtending the previous example, we can construct an LLMChain which takes user input, formats it with a PromptTemplate, and then passes the formatted response to an LLM.\\\\nfrom langchain.prompts import PromptTemplate\\\\nfrom langchain.llms import OpenAI\\\\nllm = OpenAI(temperature=0.9)\\\\nprompt = PromptTemplate(\\\\n    input_variables=[\"product\"],\\\\n    template=\"What is a good name for a company that makes {product}?\",\\\\n)\\\\nWe can now create a very simple chain that will take user input, format the prompt with it, and then send it to the LLM:\\\\nfrom langchain.chains import LLMChain\\\\nchain = LLMChain(llm=llm, prompt=prompt)\\\\nNow we can run that chain only specifying the product!\\\\nchain.run(\"colorful socks\")\\\\n# -> \\\\\\'\\\\\\\\n\\\\\\\\nSocktastic!\\\\\\'\\\\nThere we go! There’s the first chain - an LLM Chain.\\\\nThis is one of the simpler types of chains, but understanding how it works will set you up well for working with more complex chains.\\\\nFor more details, check out the getting started guide for chains.\\\\nAgents: Dynamically Call Chains Based on User Input\\\\nSo far the chains we’ve looked at run in a predetermined order.\\\\nAgents no longer do: they use an LLM to determine which actions to take and in what order. An action can either be using a tool and observing its output, or returning to the user.\\\\nWhen used correctly agents can be extremely powerful. In this tutorial, we show you how to easily use agents through the simplest, highest level API.\\', \\'source\\': \\'https://python.langchain.com/en/latest/getting_started/getting_started.html\\'}', 'metadata': {}, 'type': 'Document'}, {'page_content': \"{'id': '8106ff3953b7-21', 'text': 'that use memory.\\\\\\\\nIndexes: Language models are often more powerful when combined with your own text data - this module covers best practices for doing exactly that.\\\\\\\\nChains: Chains go beyond just a single LLM call, and are sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications.\\\\\\\\nAgents: Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain provides a standard interface for agents, a selection of agents to choose from, and examples of end to end agents.\\\\\\\\n\\\\\\\\n\\\\\\\\n\\\\\\\\n\\\\\\\\n\\\\\\\\nUse Cases#\\\\\\\\nThe above modules can be used in a variety of ways. LangChain also provides guidance and assistance in this. Below are some of the common use cases LangChain supports.\\\\\\\\n\\\\\\\\nPersonal Assistants: The main LangChain use case. Personal assistants need to take actions, remember interactions, and have knowledge about your data.\\\\\\\\nQuestion Answering: The second', 'source': 'https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/sitemap.html'}\", 'metadata': {}, 'type': 'Document'}, {'page_content': \"{'id': '81cace13f2ed-1', 'text': 'Agents: Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain provides a standard interface for agents, a selection of agents to choose from, and examples of end to end agents.\\\\nUse Cases#\\\\nThe above modules can be used in a variety of ways. LangChain also provides guidance and assistance in this. Below are some of the common use cases LangChain supports.\\\\nPersonal Assistants: The main LangChain use case. Personal assistants need to take actions, remember interactions, and have knowledge about your data.\\\\nQuestion Answering: The second big LangChain use case. Answering questions over specific documents, only utilizing the information in those documents to construct an answer.\\\\nChatbots: Since language models are good at producing text, that makes them ideal for creating chatbots.\\\\nQuerying Tabular Data: If you want to understand how to use LLMs to query data that is stored in a tabular format (csvs, SQL, dataframes, etc) you should read this page.\\\\nInteracting with APIs: Enabling LLMs to interact with APIs is extremely powerful in order to give them more up-to-date information and allow them to take actions.\\\\nExtraction: Extract structured information from text.\\\\nSummarization: Summarizing longer documents into shorter, more condensed chunks of information. A type of Data Augmented Generation.\\\\nEvaluation: Generative models are notoriously hard to evaluate with traditional metrics. One new way of evaluating them is using language models themselves to do the evaluation. LangChain provides some prompts/chains for assisting in this.\\\\nReference Docs#\\\\nAll of LangChain’s reference documentation, in one place. Full documentation on all methods, classes, installation methods, and integration setups for LangChain.\\\\nReference Documentation\\\\nLangChain Ecosystem#\\\\nGuides for how other companies/products can be used with LangChain\\\\nLangChain Ecosystem', 'source': 'https://langchain.readthedocs.io/en/latest/index.html'}\", 'metadata': {}, 'type': 'Document'}, {'page_content': '{\\'id\\': \\'f79d9582062e-1\\', \\'text\\': \\'[Document(page_content=\"ð\\\\\\\\x9f¦\\\\\\\\x9cï¸\\\\\\\\x8fð\\\\\\\\x9f”\\\\\\\\x97 LangChain\\\\\\\\n\\\\\\\\nâ\\\\\\\\x9a¡ Building applications with LLMs through composability â\\\\\\\\x9a¡\\\\\\\\n\\\\\\\\nProduction Support: As you move your LangChains into production, we\\\\\\'d love to offer more comprehensive support.\\\\\\\\nPlease fill out this form and we\\\\\\'ll set up a dedicated support Slack channel.\\\\\\\\n\\\\\\\\nQuick Install\\\\\\\\n\\\\\\\\npip install langchain\\\\\\\\n\\\\\\\\nð\\\\\\\\x9f¤” What is this?\\\\\\\\n\\\\\\\\nLarge language models (LLMs) are emerging as a transformative technology, enabling\\\\\\\\ndevelopers to build applications that they previously could not.\\\\\\\\nBut using these LLMs in isolation is often not enough to\\\\\\\\ncreate a truly powerful app - the real power comes when you can combine them with other sources of computation or knowledge.\\\\\\\\n\\\\\\\\nThis library is aimed at assisting in the development of those types of applications. Common examples of these types of applications include:\\\\\\\\n\\\\\\\\nâ\\\\\\\\x9d“ Question Answering over specific documents\\\\\\\\n\\\\\\\\nDocumentation\\\\\\\\n\\\\\\\\nEnd-to-end Example: Question Answering over Notion Database\\\\\\\\n\\\\\\\\nð\\\\\\\\x9f’¬ Chatbots\\\\\\\\n\\\\\\\\nDocumentation\\\\\\\\n\\\\\\\\nEnd-to-end Example:\\', \\'source\\': \\'https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/markdown.html\\'}', 'metadata': {}, 'type': 'Document'}]}, 'callback_events': [], 'metadata': {'run_id': '92c63591-da2c-4950-a233-95b049161ec5'}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from fastapi import FastAPI\n",
    "\n",
    "url = \"http://localhost:8000/invoke\"\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "#data = {\"question\": \"How to improve the performance of LangChain?\", 'chat_history': []} \n",
    "#data = {\"input\": \"What are the key features of LangChain?\"}\n",
    "\n",
    "data = {\"input\": {\"question\": \"What is LangChain?\"}}\n",
    "    #,\n",
    "    #\"chat_history\": [\n",
    "    #    (\"What is LangChain?\", \"LangChain is a framework for developing applications powered by language models.\"),\n",
    "    #]\n",
    "\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "168cae36-845f-44c1-a301-15bbf7c23ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LangChain is a blockchain-based platform that aims to revolutionize the language learning industry by providing a decentralized marketplace for language learning services. It allows users to connect with language tutors, exchange language learning materials, and participate in language learning communities. The platform also uses blockchain technology to ensure secure and transparent transactions between users.', response_metadata={'token_usage': {'completion_tokens': 62, 'prompt_tokens': 12, 'total_tokens': 74}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8584a9f6-f304-473a-8948-83e66758839b-0', usage_metadata={'input_tokens': 12, 'output_tokens': 62, 'total_tokens': 74})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "llm.invoke(\"What is LangChain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60a2ce9-3878-4ef8-835d-9c1688fedf5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f3492c-e03e-4649-9564-214d7da3c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit -q"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
